{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1LP5O8As-we"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "from datetime import date, timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn import tree, neighbors, datasets, linear_model,metrics, preprocessing, ensemble\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, KFold, TimeSeriesSplit\n",
    "from sklearn.metrics import plot_confusion_matrix, make_scorer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izgIpkIYf07Z"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHnUFJnPTei3"
   },
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HP3YHX4FtA1B"
   },
   "outputs": [],
   "source": [
    "air_reserve = pd.read_csv('air_reserve.csv').rename(columns={'air_store_id':'store_id'})\n",
    "hpg_reserve = pd.read_csv('hpg_reserve.csv').rename(columns={'hpg_store_id':'store_id'})\n",
    "air_store = pd.read_csv('air_store_info.csv').rename(columns={'air_store_id':'store_id'})\n",
    "hpg_store = pd.read_csv('hpg_store_info.csv').rename(columns={'hpg_store_id':'store_id'})\n",
    "air_visit = pd.read_csv('air_visit_data.csv').rename(columns={'air_store_id':'store_id'})\n",
    "store_id_map = pd.read_csv('store_id_relation.csv').set_index('hpg_store_id',drop=False)\n",
    "date_info = pd.read_csv('date_info.csv').rename(columns={'calendar_date': 'visit_date'}).drop('day_of_week',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Ct0QRh4tuOt"
   },
   "outputs": [],
   "source": [
    "# submission\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['visit_date'] = submission['id'].str[-10:]\n",
    "submission['store_id'] = submission['id'].str[:-11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--kuTKflV7py"
   },
   "source": [
    "## New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JBqJYZKTjY4"
   },
   "source": [
    "### Reserve date diff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htLsIFiGMgR1"
   },
   "outputs": [],
   "source": [
    "store_id_map = store_id_map.reset_index(drop=True)\n",
    "hpg_reserve = pd.merge(hpg_reserve, store_id_map, how='inner', left_on = 'store_id', right_on='hpg_store_id')\n",
    "hpg_reserve['visit_datetime'] = pd.to_datetime(hpg_reserve['visit_datetime'])\n",
    "hpg_reserve['visit_date'] = hpg_reserve['visit_datetime'].dt.date\n",
    "hpg_reserve['reserve_datetime'] = pd.to_datetime(hpg_reserve['reserve_datetime'])\n",
    "hpg_reserve['reserve_date'] = hpg_reserve['reserve_datetime'].dt.date\n",
    "hpg_reserve['reserve_datediff'] = hpg_reserve.apply(lambda r: (r['visit_date'] - r['reserve_date']).days, axis=1)\n",
    "hpg_reserve = hpg_reserve.groupby(['air_store_id','visit_date'], as_index=False)[['reserve_datediff', 'reserve_visitors']].sum().rename(columns={'air_store_id':'store_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-LRX2H8HIIDn"
   },
   "outputs": [],
   "source": [
    "air_reserve['visit_datetime'] = pd.to_datetime(air_reserve['visit_datetime'])\n",
    "air_reserve['visit_date'] = air_reserve['visit_datetime'].dt.date\n",
    "air_reserve['reserve_datetime'] = pd.to_datetime(air_reserve['reserve_datetime'])\n",
    "air_reserve['reserve_date'] = air_reserve['reserve_datetime'].dt.date\n",
    "air_reserve['reserve_datediff'] = air_reserve.apply(lambda r: (r['visit_date'] - r['reserve_date']).days, axis=1)\n",
    "air_reserve = air_reserve.groupby(['store_id','visit_date'], as_index=False)[['reserve_datediff', 'reserve_visitors']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pj0ps7DGVIML"
   },
   "source": [
    "### Time Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WK7pVak1t_vJ"
   },
   "outputs": [],
   "source": [
    "def weekinmonth(dates):\n",
    "    \"\"\"Get week number in a month.\n",
    "    \n",
    "    Parameters: \n",
    "        dates (pd.Series): Series of dates.\n",
    "    Returns: \n",
    "        pd.Series: Week number in a month.\n",
    "    \"\"\"\n",
    "    firstday_in_month = dates - pd.to_timedelta(dates.dt.day - 1, unit='d')\n",
    "    return (dates.dt.day-1 + firstday_in_month.dt.weekday) // 7 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bb_I0ORGN1gK"
   },
   "outputs": [],
   "source": [
    "# air_visit\n",
    "air_visit['visit_date'] = pd.to_datetime(air_visit['visit_date'],errors='coerce')\n",
    "air_visit['week_of_month'] = weekinmonth(air_visit['visit_date'])\n",
    "air_visit['dow'] = air_visit['visit_date'].dt.dayofweek\n",
    "air_visit['year'] =air_visit['visit_date'].dt.year\n",
    "air_visit['month'] = air_visit['visit_date'].dt.month\n",
    "air_visit['day_of_year'] = air_visit['visit_date'].dt.dayofyear\n",
    "air_visit['week_of_year'] = air_visit['visit_date'].dt.isocalendar().week\n",
    "air_visit['day_in_month'] = air_visit['visit_date'].dt.day\n",
    "air_visit['ttl_days_in_month'] = air_visit['visit_date'].dt.days_in_month\n",
    "air_visit['visit_date'] = air_visit['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndx8dVpCx1eG"
   },
   "outputs": [],
   "source": [
    "submission['visit_date'] = submission['id'].map(lambda x: str(x).split('_')[2])\n",
    "submission['air_store_id'] = submission['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "submission['visit_date'] = pd.to_datetime(submission['visit_date'])\n",
    "submission['week_of_month'] = weekinmonth(submission['visit_date'])\n",
    "submission['dow'] = submission['visit_date'].dt.dayofweek\n",
    "submission['year'] = submission['visit_date'].dt.year\n",
    "submission['month'] = submission['visit_date'].dt.month\n",
    "submission['day_of_year'] = submission['visit_date'].dt.dayofyear\n",
    "submission['week_of_year'] = submission['visit_date'].dt.isocalendar().week\n",
    "submission['day_in_month'] = submission['visit_date'].dt.day\n",
    "submission['ttl_days_in_month'] = submission['visit_date'].dt.days_in_month\n",
    "submission['visit_date'] = submission['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDF_tA-ITGw_"
   },
   "source": [
    "### Min, Max, Median Visitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8XSR7I6-wQz"
   },
   "outputs": [],
   "source": [
    "unique_stores = air_visit['store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'store_id': unique_stores, 'dow': [i]*len(unique_stores)}) for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 753,
     "status": "ok",
     "timestamp": 1650545892953,
     "user": {
      "displayName": "Jing Xie",
      "userId": "03267871614481759990"
     },
     "user_tz": 300
    },
    "id": "In7Yd1TY3CM8",
    "outputId": "3e1cb3fe-e651-437f-acad-3ee01d8c53c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5e6979a8-c9c2-409f-90e0-5f958d3d8eab\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>median_visitors</th>\n",
       "      <th>max_visitors</th>\n",
       "      <th>count_observations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.754386</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_25e9888d30b386df</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_8e4360a64dbd4c50</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.428571</td>\n",
       "      <td>23.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_35512c42db0868da</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.189655</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_a271c9ba19e81d17</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5798</th>\n",
       "      <td>air_168441ada3e878e1</td>\n",
       "      <td>6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>52.300000</td>\n",
       "      <td>51.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>air_6c952e3c6e590945</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.203125</td>\n",
       "      <td>14.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5800</th>\n",
       "      <td>air_0f2f96335f274801</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.650000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5801</th>\n",
       "      <td>air_c7d30ab0e07f31d5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.444444</td>\n",
       "      <td>9.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5802</th>\n",
       "      <td>air_24e8414b9b07decb</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5803 rows × 7 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e6979a8-c9c2-409f-90e0-5f958d3d8eab')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5e6979a8-c9c2-409f-90e0-5f958d3d8eab button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5e6979a8-c9c2-409f-90e0-5f958d3d8eab');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                  store_id  dow  min_visitors  mean_visitors  median_visitors  \\\n",
       "0     air_ba937bf13d40fb24    0           2.0      13.754386             12.0   \n",
       "1     air_25e9888d30b386df    0           1.0       1.666667              2.0   \n",
       "2     air_8e4360a64dbd4c50    0           2.0      24.428571             23.5   \n",
       "3     air_35512c42db0868da    0           2.0       8.189655              8.0   \n",
       "4     air_a271c9ba19e81d17    0           8.0      21.666667             20.0   \n",
       "...                    ...  ...           ...            ...              ...   \n",
       "5798  air_168441ada3e878e1    6          22.0      52.300000             51.0   \n",
       "5799  air_6c952e3c6e590945    6           1.0      13.203125             14.0   \n",
       "5800  air_0f2f96335f274801    6           1.0       4.650000              4.0   \n",
       "5801  air_c7d30ab0e07f31d5    6           1.0       8.444444              9.0   \n",
       "5802  air_24e8414b9b07decb    6           1.0       3.666667              4.0   \n",
       "\n",
       "      max_visitors  count_observations  \n",
       "0             34.0                57.0  \n",
       "1              2.0                 3.0  \n",
       "2             47.0                42.0  \n",
       "3             21.0                58.0  \n",
       "4             44.0                42.0  \n",
       "...            ...                 ...  \n",
       "5798          86.0                40.0  \n",
       "5799          38.0                64.0  \n",
       "5800          18.0                40.0  \n",
       "5801          24.0                27.0  \n",
       "5802           6.0                 3.0  \n",
       "\n",
       "[5803 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = air_visit.groupby(['store_id','dow'], as_index=False)['visitors'].min().rename(columns={'visitors':'min_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['store_id','dow']) \n",
    "tmp = air_visit.groupby(['store_id','dow'], as_index=False)['visitors'].mean().rename(columns={'visitors':'mean_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['store_id','dow'])\n",
    "tmp = air_visit.groupby(['store_id','dow'], as_index=False)['visitors'].median().rename(columns={'visitors':'median_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['store_id','dow'])\n",
    "tmp = air_visit.groupby(['store_id','dow'], as_index=False)['visitors'].max().rename(columns={'visitors':'max_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['store_id','dow'])\n",
    "tmp = air_visit.groupby(['store_id','dow'], as_index=False)['visitors'].count().rename(columns={'visitors':'count_observations'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['store_id','dow']) \n",
    "stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FhMxa8ylRsIC"
   },
   "outputs": [],
   "source": [
    "stores = pd.merge(stores, air_store, how='left', on=['store_id']) \n",
    "\n",
    "#area feature\n",
    "stores[['city', 'district', 'area']] = stores['air_area_name'].str.split(' ', 2, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1fMGZ-ISg8z"
   },
   "outputs": [],
   "source": [
    "date_info['visit_date'] = pd.to_datetime(date_info['visit_date'])\n",
    "date_info['day_of_week'] = pd.to_datetime(date_info['visit_date']).dt.dayofweek\n",
    "# convert visit_date to object \n",
    "date_info['visit_date'] = date_info['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DBBysawUuD1k"
   },
   "outputs": [],
   "source": [
    "train = pd.merge(air_visit, date_info, how='left', on=['visit_date']) \n",
    "test = pd.merge(submission, date_info, how='left', on=['visit_date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWDbFcIpTTyn"
   },
   "outputs": [],
   "source": [
    "# train = pd.merge(air_visit, stores, how='left', on=['store_id','dow']) \n",
    "# test = pd.merge(submission, stores, how='left', on=['store_id','dow'])\n",
    "train = pd.merge(train, stores, how='left', on=['store_id','dow']) \n",
    "test = pd.merge(test, stores, how='left', on=['store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bhEVoRiLiya"
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, air_reserve, how='left', on=['store_id','visit_date']) \n",
    "train = pd.merge(train, hpg_reserve, how='left', on=['store_id','visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lg6GnDGA6CSP"
   },
   "outputs": [],
   "source": [
    "test = pd.merge(test, air_reserve, how='left', on=['store_id','visit_date']) \n",
    "test = pd.merge(test, hpg_reserve, how='left', on=['store_id','visit_date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fd2eshG6_S62"
   },
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "test = test.fillna(0)\n",
    "test = test.drop(['id', 'air_store_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZgNQ2lpEJJv"
   },
   "source": [
    "### Number of restaurants of the same category within 1 km "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQKKFYyKu3bW"
   },
   "outputs": [],
   "source": [
    "from geopy.distance import distance\n",
    "\n",
    "def num_near_rest(df,n):\n",
    "  tmp = df\n",
    "  tmp[\"coordinate\"] = tuple(zip(tmp.latitude,tmp.longitude))\n",
    "  location = tmp[[\"store_id\",\"coordinate\"]].drop_duplicates()\n",
    "\n",
    "  coordinate_list = location[\"coordinate\"].tolist()\n",
    "\n",
    "  dist = []\n",
    "  for p in coordinate_list:\n",
    "    point = []\n",
    "    for pp in coordinate_list:\n",
    "      point.append(distance(p,pp).km)\n",
    "    dist.append(point)\n",
    "\n",
    "  dist_df = pd.DataFrame(dist, columns = location[\"store_id\"])\n",
    "  less1 = dist_df.apply(lambda x:x<n,axis=1).sum()\n",
    "  return pd.merge(df,less1.to_frame(name = \"restaurant_within_{0}km\".format(n)), how = 'left', on = 'store_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kgp1SCAEPhae"
   },
   "outputs": [],
   "source": [
    "# feature: number of same genre restaurants within 3km\n",
    "\n",
    "def near_rest_per_genre(df,n):\n",
    "  tmp = df\n",
    "  tmp[\"coordinate\"] = tuple(zip(tmp.latitude,tmp.longitude))\n",
    "  each_store = tmp[[\"store_id\",\"coordinate\",\"air_genre_name\"]].drop_duplicates()\n",
    "  genres = tmp[\"air_genre_name\"].unique()\n",
    "\n",
    "  genre_df = pd.DataFrame()\n",
    "\n",
    "  for genre in genres:\n",
    "\n",
    "    each_genre = each_store[each_store[\"air_genre_name\"] == genre]\n",
    "    coordinate_list = each_genre[\"coordinate\"].tolist()\n",
    "\n",
    "    dist = []\n",
    "    for p in coordinate_list:\n",
    "      point = []\n",
    "      for pp in coordinate_list:\n",
    "        point.append(distance(p,pp).km)\n",
    "      dist.append(point)\n",
    "    dist_df = pd.DataFrame(dist, columns = each_store[each_store[\"air_genre_name\"] == genre][\"store_id\"])\n",
    "    less3 = dist_df.apply(lambda x:x<n,axis=1).sum().to_frame(name = \"same_genre_restaurant_within_{0}km\".format(n))\n",
    "    \n",
    "    genre_df = pd.concat([genre_df, less3])\n",
    "  \n",
    "  return pd.merge(df,genre_df, how = 'left', on = 'store_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgAcyoirxLHp"
   },
   "outputs": [],
   "source": [
    "train_1 = num_near_rest(train,1)\n",
    "train_2 = near_rest_per_genre(train_1,1)\n",
    "test_1 = num_near_rest(test,1)\n",
    "test_2 = near_rest_per_genre(test_1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qD4azb52im5_"
   },
   "outputs": [],
   "source": [
    "test_3 = test_2\n",
    "train_3 = train_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GsVlk7DOzoA"
   },
   "source": [
    "### Adjusted dow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xHFQ816oPPy"
   },
   "outputs": [],
   "source": [
    "# tmp find unique flg == 1 and date time\n",
    "def adjust_dow(df):\n",
    "  tmp = df[['visit_date','holiday_flg']]\n",
    "  tmp = tmp[tmp.holiday_flg==1]\n",
    "  tmp = tmp['visit_date'].unique()\n",
    "  f1 = lambda x: x - datetime.timedelta(1)\n",
    "  f2 = lambda x: x + datetime.timedelta(1)\n",
    "  # before1d find the date before holiday 1 day\n",
    "  # after1d find the date after holiday 1 day\n",
    "  before1d = f1(tmp)\n",
    "  after1d = f2(tmp)\n",
    "  # find before1d row and day of week in monday - thursday change it to friday\n",
    "  # find after1d row and day of week in tuesday - friday change it to monday\n",
    "  df.loc[(df.visit_date.isin(after1d)) & (df.day_of_week.isin([1,2,3,4]) & (df.holiday_flg == 0)),'day_of_week'] = 0\n",
    "  df.loc[(df.visit_date.isin(before1d)) & (df.day_of_week.isin([0,1,2,3]) & (df.holiday_flg == 0)),'day_of_week']= 4\n",
    "  df.loc[(df.visit_date.isin(tmp)),'day_of_week'] = 5\n",
    "  df = df.rename(columns={'day_of_week':\"adjusted_dow\"})\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHxWiaNmoVAq"
   },
   "outputs": [],
   "source": [
    "train_df = adjust_dow(train_3)\n",
    "test_df = adjust_dow(test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FT2uVPKgVh-"
   },
   "source": [
    "### Min, Max, Mean, and Std of the number of visitors in the same area/ same month/ same dow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tr1gNZknYZAz"
   },
   "outputs": [],
   "source": [
    "tmp = train_df[['dow','air_genre_name','visitors','month']]\n",
    "tmp = tmp.groupby(['air_genre_name', 'dow','month'], as_index=False)['visitors'].agg(['min','max','mean','std']).fillna(0)\n",
    "tmp = tmp.reset_index()\n",
    "tmp = tmp.rename(columns = {'min':'genre_dow_mon_min','max':'genre_dow_mon_max','mean':'genre_dow_mon_mean','std':'genre_dow_mon_std'})\n",
    "train_df = pd.merge(train_df, tmp, how='left', on=['air_genre_name', 'dow','month']) \n",
    "test_df = pd.merge(test_df, tmp, how='left', on=['air_genre_name', 'dow','month']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HSYsb4UEthh"
   },
   "source": [
    "### Weather for each restaurant per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KjjLBAE7v6gm"
   },
   "outputs": [],
   "source": [
    "# feature: weather\n",
    "weather_data = pd.read_csv('WeatherData.csv', parse_dates=['calendar_date'])\n",
    "weather_data.columns = weather_data.columns.str.replace('area_name', 'station_id')\n",
    "hpg_nearest = pd.read_csv('hpg_store_info_with_nearest_active_station.csv')\n",
    "air_nearest = pd.read_csv('air_store_info_with_nearest_active_station.csv')\n",
    "hpg_nearest.rename(columns={'hpg_store_id':'air_store_id', \n",
    "                            'hpg_genre_name': 'air_genre_name', \n",
    "                            'hpg_area_name': 'air_area_name'}, inplace=True)\n",
    "nearest = pd.concat([air_nearest, hpg_nearest])\n",
    "nearest = nearest.rename(columns = {'air_store_id':'store_id'}).copy()\n",
    "train_weather = pd.merge(train_df, nearest.iloc[:, [0,7]], how = 'left', on='store_id')\n",
    "test_weather = pd.merge(test_df, nearest.iloc[:, [0,7]], how = 'left', on='store_id')\n",
    "train_weather['visit_date']=pd.to_datetime(train_weather['visit_date'])\n",
    "test_weather['visit_date']=pd.to_datetime(test_weather['visit_date'])\n",
    "\n",
    "# add weather\n",
    "weather_station_data_filled = weather_data.interpolate(method='pad')\n",
    "weather_station_data_filled = weather_station_data_filled[['station_id','calendar_date','precipitation','avg_temperature','hours_sunlight','avg_wind_speed',\n",
    "                      'high_temperature','low_temperature','solar_radiation','avg_humidity','cloud_cover']]\n",
    "\n",
    "train_weather2 = pd.merge(train_weather, weather_station_data_filled, how='left', \n",
    "                          left_on=['station_id', 'visit_date'], right_on=['station_id','calendar_date'])\n",
    "\n",
    "test_weather2 = pd.merge(test_weather, weather_station_data_filled, how='left', \n",
    "                          left_on=['station_id', 'visit_date'], right_on=['station_id','calendar_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jKz3YwLk4XWu"
   },
   "outputs": [],
   "source": [
    "train_final = train_weather2 \n",
    "test_final = test_weather2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NF0wNbThWsbX"
   },
   "source": [
    "\n",
    "\n",
    "### Lag features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4EjJMymPJC6"
   },
   "outputs": [],
   "source": [
    "combined = pd.concat([train_final, test_final]).copy()\n",
    "combined['lag_42'] = combined.groupby('store_id')['visitors'].shift(42)\n",
    "combined['lag_168'] = combined.groupby('store_id')['visitors'].shift(168)\n",
    "fill=combined[(combined['store_id']=='air_900d755ebd2f7bbd')&(combined['visit_date']>='2017-04-12')&(combined['visit_date']<='2017-04-22')]['visitors'].mean()\n",
    "ids = combined[combined['lag_42'].isna()][(combined[combined['lag_42'].isna()]['visit_date']>='2017-04-23')&(combined[combined['lag_42'].isna()]['store_id']=='air_900d755ebd2f7bbd')].index\n",
    "combined.loc[ids, 'lag_42']=fill\n",
    "combined_filled = combined.interpolate(method='pad')\n",
    "train_final = combined_filled[combined_filled['visit_date']< '2017-04-23']\n",
    "test_final = combined_filled[combined_filled['visit_date']>= '2017-04-23']\n",
    "train_final.isna().sum(0) \n",
    "train_final=train_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1650546331204,
     "user": {
      "displayName": "Jing Xie",
      "userId": "03267871614481759990"
     },
     "user_tz": 300
    },
    "id": "u5lOGfUZTVLB",
    "outputId": "2737299c-3d9f-4af2-8d9f-d9d78539ffad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((251940, 49), (32019, 49))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.shape,test_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbVQd5jIQ7WO"
   },
   "source": [
    "### Final features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1650546331214,
     "user": {
      "displayName": "Jing Xie",
      "userId": "03267871614481759990"
     },
     "user_tz": 300
    },
    "id": "esUhUmnYRxPT",
    "outputId": "a7022f12-1918-4f7e-ed98-34f472a780f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "train_final.drop(['visit_date','coordinate','station_id','calendar_date'],axis=1,inplace=True)\n",
    "test_final.drop(['visit_date','coordinate','station_id','calendar_date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ne2yZI7pDgk"
   },
   "source": [
    "### Final Feature processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1650546331629,
     "user": {
      "displayName": "Jing Xie",
      "userId": "03267871614481759990"
     },
     "user_tz": 300
    },
    "id": "TCVTFONQoQ24",
    "outputId": "8ae8148f-ae16-41fc-caf7-32ca960a0d75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_final['week_of_year']=train_final['week_of_year'].astype(float)\n",
    "test_final['week_of_year']=test_final['week_of_year'].astype(float)\n",
    "train_final['store_id']=train_final['store_id'].astype('category')\n",
    "test_final['store_id']=test_final['store_id'].astype('category')\n",
    "train_final['air_genre_name']=train_final['air_genre_name'].astype('category')\n",
    "test_final['air_genre_name']=test_final['air_genre_name'].astype('category')\n",
    "train_final['air_area_name']=train_final['air_area_name'].astype('category')\n",
    "test_final['air_area_name']=test_final['air_area_name'].astype('category')\n",
    "train_final['city']=train_final['city'].astype('category')\n",
    "test_final['city']=test_final['city'].astype('category')\n",
    "train_final['district']=train_final['district'].astype('category')\n",
    "test_final['district']=test_final['district'].astype('category')\n",
    "train_final['area']=train_final['area'].astype('category')\n",
    "test_final['area']=test_final['area'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1650546332025,
     "user": {
      "displayName": "Jing Xie",
      "userId": "03267871614481759990"
     },
     "user_tz": 300
    },
    "id": "-K313dg9pJop",
    "outputId": "844fbc04-48be-4774-bad6-43bfa7e8c6c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# LabelEncoder\n",
    "lbl = LabelEncoder()\n",
    "\n",
    "train_final['store_id'] = lbl.fit_transform(train_final['store_id'])\n",
    "test_final['store_id'] = lbl.fit_transform(test_final['store_id'])\n",
    "train_final['air_genre_name'] = lbl.fit_transform(train_final['air_genre_name'])\n",
    "test_final['air_genre_name'] = lbl.fit_transform(test_final['air_genre_name'])\n",
    "train_final['air_area_name'] = lbl.fit_transform(train_final['air_area_name'])\n",
    "test_final['air_area_name'] = lbl.fit_transform(test_final['air_area_name'])\n",
    "train_final['city'] = lbl.fit_transform(train_final['city'])\n",
    "test_final['city'] = lbl.fit_transform(test_final['city'])\n",
    "train_final['district'] = lbl.fit_transform(train_final['district'])\n",
    "test_final['district'] = lbl.fit_transform(test_final['district'])\n",
    "train_final['area'] = lbl.fit_transform(train_final['area'])\n",
    "test_final['area'] = lbl.fit_transform(test_final['area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zePXgc-wpozA"
   },
   "outputs": [],
   "source": [
    "predictors = [f for f in train_final.columns if f not in (['visitors'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxjRG33XpVFM"
   },
   "outputs": [],
   "source": [
    "#Normalize training data\n",
    "normalizer = preprocessing.Normalizer()\n",
    "normalized_X_train = normalizer.fit_transform(train_final[predictors])\n",
    "\n",
    "#Normalize testing data using the training data’s max and min. \n",
    "normalized_X_test = normalizer.transform(test_final[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uK962gwWmtLL"
   },
   "outputs": [],
   "source": [
    "train_final['visitors'] = np.log1p(train_final['visitors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJ5x0h7dWKmC"
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujls_JGOyuut"
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MC3YJEaJxA96"
   },
   "outputs": [],
   "source": [
    "model2 = neighbors.KNeighborsRegressor(n_jobs=-1, n_neighbors=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3L18-y0kyw9F"
   },
   "outputs": [],
   "source": [
    "model2.fit(train_final[predictors], train_final['visitors'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJHJIa8Ky3yT"
   },
   "outputs": [],
   "source": [
    "predicted_train_y = model2.predict(train_final[predictors])\n",
    "print('RMSLE score on training data:', round(\n",
    "    metrics.mean_squared_log_error(train_final['visitors'], \n",
    "                                   predicted_train_y, squared=False),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kO8kxX-_UYsM"
   },
   "outputs": [],
   "source": [
    "pred2 = model2.predict(test_final[predictors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb9m1xCEsqhA"
   },
   "source": [
    "### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LsqYQ-Rosphm"
   },
   "outputs": [],
   "source": [
    "model1 = ensemble.GradientBoostingRegressor(learning_rate=0.2, random_state=3,\n",
    "                    n_estimators=180, subsample=0.78, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ug-OQa7tt_5i"
   },
   "outputs": [],
   "source": [
    "model1.fit(train_final[predictors], train_final['visitors'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJugfMvzv-RO"
   },
   "outputs": [],
   "source": [
    "predicted_train_y = model1.predict(train_final[predictors])\n",
    "print('RMSLE score on training data:', round(metrics.mean_squared_log_error(\n",
    "    train_final['visitors'], predicted_train_y, squared=False),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LD6vpJnwqDX"
   },
   "outputs": [],
   "source": [
    "pred1 = model1.predict(test_final[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPuAOROWwiXl"
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['visitors']=np.expm1(pred1)\n",
    "sub['visitors'] =sub['visitors'].fillna(0)\n",
    "sub.to_csv(r'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDUDq_YIiQfZ"
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6DbX5HBiTyj"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDhbbfrJjTKo"
   },
   "outputs": [],
   "source": [
    "model4 = xgb.XGBRegressor(learning_rate=0.2, random_state=3, n_estimators=280, subsample=0.8, \n",
    "                      colsample_bytree=0.8, max_depth =5)\n",
    "model4.fit(train_final[predictors], train_final['visitors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7Pvm1umkvh0"
   },
   "outputs": [],
   "source": [
    "predicted_train_y = model4.predict(train_final[predictors])\n",
    "print('RMSLE score on training data:', round(metrics.mean_squared_log_error(train_final['visitors'], predicted_train_y, squared=False),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2okZRVjqLHBW"
   },
   "outputs": [],
   "source": [
    "pred4 = model4.predict(test_final[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yalzOLtbMxBD"
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['visitors']=np.expm1(pred4)\n",
    "sub['visitors'] =sub['visitors'].fillna(0)\n",
    "sub.to_csv(r'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOygr8pjz_Oi"
   },
   "source": [
    "#### BaysianOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lS1rv7lDwfuM"
   },
   "outputs": [],
   "source": [
    "params={'max_depth':[3,10],\n",
    "      'gamma':[0.1,1],\n",
    "      'n_estimators':[100,200],\n",
    "      'subsample':[0.8],\n",
    "      'eta':[0.1],\n",
    "      'eval_metric':['rmse']}\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "bayes_search = BayesSearchCV(estimator=xgb.XGBRegressor(), search_spaces=params,\n",
    "                             n_jobs=-1, cv=tscv, verbose=1)\n",
    "bayes_search.fit(train_df[predictors], train_df['visitors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEj78AtGiwN2"
   },
   "source": [
    "### LightGBM GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvEIDcLjPYq4"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXzMTm7mNMz2"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': [30,60,120],\n",
    "    'subsample':[0.8],\n",
    "    'learning_rate':[0.07,0.06,0.05],\n",
    "    'max_depth':[5,6,7],\n",
    "    'metric': ['rmse'],\n",
    "    'objective': ['regression'],\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'min_child_weight':[16]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mkup11v1AfQ5"
   },
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "model = lgb.LGBMRegressor()\n",
    "model_clf = GridSearchCV(estimator=model, param_grid=param_grid, \n",
    "                         scoring='neg_mean_squared_log_error', cv=tscv, n_jobs=-1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "executionInfo": {
     "elapsed": 382789,
     "status": "error",
     "timestamp": 1650500710871,
     "user": {
      "displayName": "Jing Xie",
      "userId": "03267871614481759990"
     },
     "user_tz": 300
    },
    "id": "z67e5JqcAiu9",
    "outputId": "eabf26a6-5b08-4e31-bb60-892a64e8f133"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-b10dcde7a4fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfitted_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'visitors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    683\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                                        callbacks=callbacks)\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0;32m-> 1552\u001b[0;31m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    999\u001b[0m                                 \u001b[0minit_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                                 \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[1;32m   1002\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_from_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_from_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_from_list_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init_from_np2d\u001b[0;34m(self, mat, params_str, ref_dataset)\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0mref_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m             ctypes.byref(self.handle)))\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fitted_model = model_clf.fit(train_final[predictors], train_final['visitors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-hCx17gBtca"
   },
   "outputs": [],
   "source": [
    "pred = fitted_model.predict(test_final[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfWvImGtB0Ja"
   },
   "outputs": [],
   "source": [
    "predicted_train_y = fitted_model.predict(train_final[predictors])\n",
    "predicted_train_y = np.where(predicted_train_y<0, 0, predicted_train_y)\n",
    "# RMSLE score on training data\n",
    "print('RMSLE score on training data:', round(metrics.mean_squared_log_error(train_final['visitors'], predicted_train_y, squared=False),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkYVLswiB2pj"
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['visitors']=pred\n",
    "sub['visitors'] =sub['visitors'].fillna(0)\n",
    "sub.to_csv(r'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-Xjvs7aU6_4"
   },
   "outputs": [],
   "source": [
    "fitted_model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPDHADH0AQjx"
   },
   "source": [
    "### Run final LightGBM with best set of params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqCEMQk5uBFX"
   },
   "outputs": [],
   "source": [
    "# params from Japanese notebook\n",
    "params = {\n",
    "    'objective':'regression',\n",
    "    'num_leaves':60,\n",
    "    'learning_rate':0.01,\n",
    "    'n_estimators':10000\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNtitayyT7RQ"
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train_final[predictors], train_final['visitors'])\n",
    "# lgb_test = lgb.Dataset(test_final[predictors], test_final['visitors'])\n",
    "\n",
    "gbm = lgb.train(params, lgb_train, 2300)\n",
    "pred = gbm.predict(test_final[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWLIfyH7UWp6"
   },
   "outputs": [],
   "source": [
    "predicted_train_y = gbm.predict(train_final[predictors])\n",
    "predicted_train_y = np.where(predicted_train_y<0, 0, predicted_train_y)\n",
    "# RMSLE score on training data\n",
    "print('RMSLE score on training data:', round(metrics.mean_squared_log_error(train_final['visitors'], predicted_train_y, squared=False),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "825xuc8mAi4-"
   },
   "outputs": [],
   "source": [
    "lgb.plot_importance(gbm, figsize=(10,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjItnb41UWuW"
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['visitors']=np.expm1(pred)\n",
    "sub['visitors'] =sub['visitors'].fillna(0)\n",
    "sub.to_csv(r'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6psn0PhcS9s"
   },
   "source": [
    "# Stacking of KNN, Gradient Boosting and XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ensZCq0jAqVF"
   },
   "outputs": [],
   "source": [
    "# initialize two models to be stacked\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "knn = neighbors.KNeighborsRegressor(n_jobs=-1, n_neighbors=4)\n",
    "gb = ensemble.GradientBoostingRegressor(learning_rate=0.2, random_state=3,\n",
    "                    n_estimators=180, subsample=0.78, max_depth=5)\n",
    "lgbr = lgb.LGBMRegressor(objective='regression',\n",
    "                                         num_leaves=60,learning_rate=0.01,\n",
    "                                         n_estimators=10000)\n",
    "xgbr = xgb.XGBRegressor(max_depth=3,gamma=0.1, n_estimators=200, \n",
    "                        subsample=0.8,eta=0.1,eval_metric='rmse')\n",
    "\n",
    "X, y = train_final[predictors], train_final['visitors']\n",
    "\n",
    "# generate cross-val-prediction with rf and gb using TimeSeriesSplit\n",
    "cross_val_predict = np.row_stack([\n",
    "    np.column_stack([\n",
    "        knn.fit(X.iloc[id_train], y.iloc[id_train]).predict(X.iloc[id_test]),\n",
    "        gb.fit(X.iloc[id_train], y.iloc[id_train]).predict(X.iloc[id_test]),\n",
    "        lgbr.fit(X.iloc[id_train], y.iloc[id_train]).predict(X.iloc[id_test]),\n",
    "        xgbr.fit(X.iloc[id_train], y.iloc[id_train]).predict(X.iloc[id_test]),\n",
    "        y[id_test]  # we add in the last position the corresponding fold labels\n",
    "    ])\n",
    "    for id_train,id_test in TimeSeriesSplit(n_splits=3).split(X)\n",
    "])  # (test_size*n_splits, n_models_to_stack+1)\n",
    "\n",
    "# final fit rf and gb with all the available data\n",
    "knn.fit(X,y)\n",
    "gb.fit(X,y)\n",
    "lgbr.fit(X,y)\n",
    "xgbr.fit(X,y)\n",
    "\n",
    "# fit a linear stacking on cross_val_predict\n",
    "stacking = SVR()\n",
    "stacking.fit(cross_val_predict[:,:-1], cross_val_predict[:,-1])\n",
    "\n",
    "# how generate predictions on new unseen data\n",
    "pred = stacking.predict(\n",
    "    np.column_stack([\n",
    "        knn.predict(test_final[predictors]),\n",
    "        gb.predict(test_final[predictors]),\n",
    "        lgbr.predict(test_final[predictors]),\n",
    "        xgbr.predict(test_final[predictors])\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUfJdUBnYHHf"
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['visitors']=np.expm1(pred)\n",
    "sub['visitors'] =sub['visitors'].fillna(0)\n",
    "sub.to_csv(r'submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "My_project_featuers.ipynb",
   "provenance": [
    {
     "file_id": "1gceUh4gCE_2-5CRx7dfxBPfItnwRcSAn",
     "timestamp": 1650313121582
    },
    {
     "file_id": "1KOjIvYzlCUgtkghiXjt_kEmpLcwVmDU4",
     "timestamp": 1649041804003
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
